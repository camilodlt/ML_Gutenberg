{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "## PREREQUISITES\n",
                "We have to install the new spacy version for python. \n",
                "\n",
                "We also need a language model, in this case I use fr_core_news_lg. \n",
                "\n",
                "At the end of this part, we use spacy's validate to assess compatibility. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "#%%capture\n",
                "## UPDATES --- \n",
                "#!conda install -y -c conda-forge spacy\n",
                "#!conda install -c pytorch torchtext -y \n",
                "#!conda install -y -c conda-forge scikit-learn \n",
                "#!conda install -y -c anaconda numpy"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "#%%capture\n",
                "# SPACY LANGUAGE ------ \n",
                "    #* Downloads 571 MB  \n",
                "#!python -m spacy download fr_core_news_lg # Maybe try fr_dep_news_trf\n",
                "# More info at https://spacy.io/usage/models "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Spacy's validate command tells us that fr_core_news_lg is compatible with the version of spacy that is installed (3.1.0)."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "# VERIFY SPACY ------ \n",
                "!python -m spacy validate"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
                        "\u001b[1m\n",
                        "================= Installed pipeline packages (spaCy v3.1.1) =================\u001b[0m\n",
                        "\u001b[38;5;4mℹ spaCy installation:\n",
                        "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/spacy\u001b[0m\n",
                        "\n",
                        "NAME              SPACY            VERSION                            \n",
                        "fr_core_news_lg   >=3.1.0,<3.2.0   \u001b[38;5;2m3.1.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "# SPACY INFO ------ \n",
                "!python -m spacy info \n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\u001b[1m\n",
                        "============================== Info about spaCy ==============================\u001b[0m\n",
                        "\n",
                        "spaCy version    3.1.1                         \n",
                        "Location         /opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/spacy\n",
                        "Platform         Linux-5.11.0-27-generic-x86_64-with-debian-stretch-sid\n",
                        "Python version   3.6.11                        \n",
                        "Pipelines        fr_core_news_lg (3.1.0)       \n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### LIBRARIES"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "# LIBRARIES ------\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torchtext.datasets import Multi30k\n",
                "from torchtext.legacy.data import Field, BucketIterator\n",
                "import numpy as np\n",
                "import spacy\n",
                "import random\n",
                "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
                "from torchtext.data.utils import get_tokenizer\n",
                "from collections import Counter\n",
                "from torchtext.vocab import Vocab\n",
                "#from torchtext.utils import download_from_url, extract_archive\n",
                "import io\n",
                "#from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### GET THE DATA \n",
                "sample_path= \"/home/camilo/Documents/Own Projects/Gutenberg 2/ML_GutenbergFR/data_output/Normal/Sample_ML.txt\"\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "# TORCH, GPU INFORMATION ------\n",
                "print(\n",
                "torch.__version__,\n",
                "torch.cuda.current_device(),\n",
                "torch.cuda.device(0),\n",
                "torch.cuda.device_count(),\n",
                "torch.cuda.get_device_name(0)\n",
                ")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "1.9.0 0 <torch.cuda.device object at 0x7fab1c653e10> 1 Quadro P400\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### PATHS ------"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "train_filepaths = \"/home/camilo/Documents/Own Projects/Gutenberg 2/ML_GutenbergFR/data_output/Normal/Sample_ML.txt\""
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### TOKENIZER"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "We use the language model that we downloaded. In this case it is the french corpus trained on news and media sources. \n",
                "\n",
                "As we can see, the tokenizer keeps, by default, uppercase and punctuation."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "# TOKENIZER ------\n",
                "#spacy_lang = spacy.load(\"fr_core_news_lg\")\n",
                "#def tokenize_fr(text):\n",
                "#    return [tok.text for tok in spacy_lang.tokenizer(text)]\n",
                "#* Example --- \n",
                "#tokenize_fr(\"Bonjour, ceci est un exemple. ...  \")\n",
                "\n",
                "# NEW \n",
                "def split(word):\n",
                "    return list(word)\n",
                "tokenizer=get_tokenizer(split)\n",
                "tokenizer(\"hello bye\")"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "['h', 'e', 'l', 'l', 'o', ' ', 'b', 'y', 'e']"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 8
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "### VOCAB AT CHARACTER LEVEL ------ \n",
                "from torchtext.vocab import build_vocab_from_iterator\n",
                "\n",
                "def build_vocab(filepath, tokenizer, pos):\n",
                "  #counter = Counter()\n",
                "  with io.open(filepath, encoding=\"utf8\") as f:\n",
                "    for string_ in f:\n",
                "      string_= string_.split(\", ,\")[pos]\n",
                "      yield tokenizer(string_)\n",
                "  #return Vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
                "  #return Vocab(counter)\n",
                "fr_char_vocab=build_vocab_from_iterator(build_vocab(train_filepaths, tokenizer, pos=0),specials=['<unk>', '<pad>', '<bos>', '<eos>','\\n'] )\n",
                "#fr_char_vocab = build_vocab(train_filepaths, tokenizer)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "print(\"Number of characters in the vocab :\",fr_char_vocab.__len__())"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Number of characters in the vocab : 53\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "out_index=fr_char_vocab[\"<unk>\"]\n",
                "fr_char_vocab.set_default_index(out_index)\n",
                "fr_char_vocab[\"hello\"] # => 0 because \"<unk>\" is 0... "
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "0"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 11
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "def split_T_from_F(sentence,pos):\n",
                "    string_= sentence.split(\", ,\")[pos]\n",
                "    return string_\n",
                "\n",
                "def data_process(filepath):\n",
                "  raw_iter = iter(io.open(filepath, encoding=\"utf8\"))\n",
                "  data = []\n",
                "  for raw_sentence in raw_iter:\n",
                "    T_sentence_tensor = torch.tensor([fr_char_vocab[token] for token in tokenizer(split_T_from_F(raw_sentence,0))],\n",
                "                            dtype=torch.long)\n",
                "    F_sentence_tensor = torch.tensor([fr_char_vocab[token] for token in tokenizer(split_T_from_F(raw_sentence,1))],\n",
                "                            dtype=torch.long)\n",
                "    data.append((T_sentence_tensor,F_sentence_tensor))\n",
                "  return data\n",
                "\n",
                "train_data = data_process(train_filepaths)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "# VERIF => Truth Mistake\n",
                "print(train_data[0])\n",
                "\n",
                "print([fr_char_vocab[token] for token in tokenizer(\"Truth\")])\n",
                "print([fr_char_vocab[token] for token in tokenizer(\"Mistake\\n\")])"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "(tensor([47, 12, 13, 10, 26]), tensor([ 0,  9,  8, 10,  7, 44,  6,  4]))\n",
                        "[47, 12, 13, 10, 26]\n",
                        "[0, 9, 8, 10, 7, 44, 6, 4]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "source": [
                "import torch\n",
                "from sklearn.model_selection import train_test_split\n",
                "from torch.utils.data import Subset\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "\n",
                "BATCH_SIZE = 128\n",
                "PAD_IDX = fr_char_vocab['<pad>']\n",
                "BOS_IDX = fr_char_vocab['<bos>']\n",
                "EOS_IDX = fr_char_vocab['<eos>']\n",
                "\n",
                "from torch.nn.utils.rnn import pad_sequence\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "def generate_batch(data_batch):\n",
                "  T_batch, F_batch = [], []\n",
                "  for (T_item, F_item) in data_batch:\n",
                "    T_batch.append(torch.cat([torch.tensor([BOS_IDX]), T_item, torch.tensor([EOS_IDX])], dim=0)) # \n",
                "    F_batch.append(torch.cat([torch.tensor([BOS_IDX]), F_item, torch.tensor([EOS_IDX])], dim=0))\n",
                "  T_batch = pad_sequence(T_batch, padding_value=PAD_IDX)\n",
                "  F_batch = pad_sequence(F_batch, padding_value=PAD_IDX)\n",
                "  return F_batch, T_batch\n",
                "\n",
                "def train_val_dataset(dataset, val_split=0.25):\n",
                "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
                "    datasets = {}\n",
                "    datasets['train'] = Subset(dataset, train_idx)\n",
                "    datasets['val'] = Subset(dataset, val_idx)\n",
                "    return datasets\n",
                "\n",
                "datasets = train_val_dataset(train_data)\n",
                "\n",
                "train_iter = DataLoader(datasets[\"train\"], batch_size=BATCH_SIZE,\n",
                "                        shuffle=False, collate_fn=generate_batch)\n",
                "valid_iter = DataLoader(datasets[\"val\"], batch_size=BATCH_SIZE,\n",
                "                        shuffle=True, collate_fn=generate_batch)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "source": [
                "for i,content in enumerate(train_iter):\n",
                "    if(i==0):\n",
                "        print(content[0].shape)\n",
                "        print(content[1].shape)\n",
                "        print(content[0][0])\n",
                "        print(content[0][1])\n",
                "fr_char_vocab.vocab.lookup_token(2)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "torch.Size([75, 128])\n",
                        "torch.Size([71, 128])\n",
                        "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
                        "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
                        "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
                        "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
                        "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
                        "        2, 2, 2, 2, 2, 2, 2, 2])\n",
                        "tensor([21, 19, 22, 14, 13, 18, 15, 15, 19,  6, 32, 16, 10, 16, 23, 23, 16, 13,\n",
                        "        18,  7, 14, 14, 14, 19,  8, 10, 16,  6, 19, 11, 16, 13, 18, 14,  7, 25,\n",
                        "        16, 11, 17, 27,  8, 19, 14, 43, 27, 17,  8, 27, 17, 10, 14, 21, 14, 17,\n",
                        "        14, 19,  8, 19, 19,  7,  9, 11, 18, 16, 14, 14,  7, 22,  6, 14, 25, 20,\n",
                        "         8,  7, 16, 38, 16, 16, 26, 19, 18, 24,  8, 16, 18,  8, 27, 14, 10, 24,\n",
                        "        16, 14, 14,  8,  7, 19, 18, 14, 10, 16, 10, 29,  6, 19, 17, 16,  7,  7,\n",
                        "         7,  7,  7, 19, 23, 14, 16, 10,  8,  8, 16, 17, 21, 22,  7, 19,  0, 14,\n",
                        "        11,  9])\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'<bos>'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 61
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "### GET THE DATA \n",
                "#sample_path= \"/home/camilo/Documents/Own Projects/Gutenberg 2/ML_GutenbergFR/data_output/Normal/Sample_ML.txt\"\n",
                "#import pandas as pd \n",
                "#sample_data = pd.read_csv(sample_path, sep=\", ,\")\n",
                "#train_data= sample_data.iloc[0:800]\n",
                "#valid_data= sample_data.iloc[800:]"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
                        "  after removing the cwd from sys.path.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### ENCODER"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "source": [
                "# ENCODER ------\n",
                "class Encoder(nn.Module):\n",
                "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
                "        super(Encoder, self).__init__()\n",
                "        self.dropout = nn.Dropout(p)\n",
                "        self.hidden_size = hidden_size # FOR LSTM : hidden and cell states\n",
                "        self.num_layers = num_layers # FOR LSTM : layers\n",
                "\n",
                "        self.embedding = nn.Embedding(input_size, embedding_size) # Char representation in embedding space\n",
                "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p) # recurrent layers\n",
                "\n",
                "    def forward(self, x):\n",
                "        # x shape: (seq_length, N) where N is batch size\n",
                "\n",
                "        embedding = self.dropout(self.embedding(x))\n",
                "        # embedding shape: (seq_length, N, embedding_size)\n",
                "\n",
                "        outputs, (hidden, cell) = self.rnn(embedding) # h and c states init randomly\n",
                "        # outputs shape: (seq_length, N, hidden_size) => discarded\n",
                "        # hidden shape: [num_layers* n_directions (1), N, hidden_size]\n",
                "        return hidden, cell"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 118,
            "source": [
                "next(iter(train_iter))[0].shape\n",
                "x= Encoder(len(fr_char_vocab),10,20,5,0.2)\n",
                "temp_result=x.forward(next(iter(train_iter))[0])\n",
                "h= temp_result[0]\n",
                "c= temp_result[1]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 110,
            "source": [
                "print(h.shape)\n",
                "print(c.shape)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "torch.Size([5, 128, 20])\n",
                        "torch.Size([5, 128, 20])\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### DECODER"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 119,
            "source": [
                "class Decoder(nn.Module):\n",
                "    def __init__(\n",
                "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
                "    ):\n",
                "        super(Decoder, self).__init__()\n",
                "        self.dropout = nn.Dropout(p)\n",
                "        self.hidden_size = hidden_size # For LSTM : hidden and cell states\n",
                "        self.num_layers = num_layers # for LSTM : layers to connect \n",
                "\n",
                "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
                "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
                "        self.fc = nn.Linear(hidden_size, output_size) # To have a fixed size output\n",
                "\n",
                "    def forward(self, x, hidden, cell):\n",
                "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
                "        # is 1 here because we are sending in a single word and not a sentence\n",
                "        x = x.unsqueeze(0)\n",
                "\n",
                "        embedding = self.dropout(self.embedding(x))\n",
                "        # embedding shape: (1, N, embedding_size)\n",
                "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell)) # this time we pass h and c states from the encoder\n",
                "        # outputs shape: (1, N, hidden_size) \"!!!\" because we pass only a \"character\" => sequence length = 1 time-step\n",
                "\n",
                "        predictions = self.fc(outputs)\n",
                "\n",
                "        # predictions shape: (1, N, length_target_vocabulary) to send it to\n",
                "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
                "        # just gonna remove the first dim\n",
                "        predictions = predictions.squeeze(0)\n",
                "\n",
                "        return predictions, hidden, cell"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 120,
            "source": [
                "next(iter(train_iter))[0].shape"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "torch.Size([75, 128])"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 120
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 121,
            "source": [
                "dec= Decoder(75,10,20,len(fr_char_vocab.vocab),5,0.25)\n",
                "x=dec.forward(next(iter(train_iter))[0][0], h,c)\n",
                "x[0].shape # predictions "
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "torch.Size([128, 53])"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 121
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### SEQ2SEQ"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 107,
            "source": [
                "class Seq2Seq(nn.Module):\n",
                "    def __init__(self, encoder, decoder):\n",
                "        super(Seq2Seq, self).__init__()\n",
                "        self.encoder = encoder\n",
                "        self.decoder = decoder\n",
                "\n",
                "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
                "        batch_size = source.shape[1]\n",
                "        target_len = target.shape[0]\n",
                "        target_vocab_size = len(fr_char_vocab.vocab)\n",
                "\n",
                "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
                "\n",
                "        hidden, cell = self.encoder(source)\n",
                "\n",
                "        # Grab the first input to the Decoder which will be <SOS> token\n",
                "        x = target[0]\n",
                "        print(x.shape) # 1, batch\n",
                "\n",
                "        for t in range(1, target_len):\n",
                "            # Use previous hidden, cell as context from encoder at start\n",
                "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
                "\n",
                "            # Store next output prediction\n",
                "            outputs[t] = output\n",
                "\n",
                "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
                "            best_guess = output.argmax(1)\n",
                "\n",
                "            # With probability of teacher_force_ratio we take the actual next word\n",
                "            # otherwise we take the word that the Decoder predicted it to be.\n",
                "            # Teacher Forcing is used so that the model gets used to seeing\n",
                "            # similar inputs at training and testing time, if teacher forcing is 1\n",
                "            # then inputs at test time might be completely different than what the\n",
                "            # network is used to. This was a long comment.\n",
                "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
                "\n",
                "        return outputs"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 152,
            "source": [
                "\n",
                "### We're ready to define everything we need for training our Seq2Seq model ###\n",
                "\n",
                "# Training hyperparameters\n",
                "num_epochs = 5\n",
                "learning_rate = 0.001\n",
                "batch_size = 8\n",
                "\n",
                "# Model hyperparameters\n",
                "load_model = False\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "input_size_encoder = len(fr_char_vocab.vocab)\n",
                "input_size_decoder = len(fr_char_vocab.vocab)\n",
                "output_size = len(fr_char_vocab.vocab)\n",
                "encoder_embedding_size = 10\n",
                "decoder_embedding_size = 10\n",
                "hidden_size = 64  # Needs to be the same for both RNN's\n",
                "num_layers = 2\n",
                "enc_dropout = 0.5\n",
                "dec_dropout = 0.5\n",
                "\n",
                "# Tensorboard to get nice loss plot\n",
                "writer = SummaryWriter(f\"runs/loss_plot\")\n",
                "step = 0\n",
                "\n",
                "train_iterator, valid_iterator = BucketIterator.splits(\n",
                "    (datasets[\"train\"], datasets[\"val\"]),\n",
                "    batch_size=batch_size,\n",
                "    sort_within_batch=True,\n",
                "    sort_key=lambda x: len(x),\n",
                "    device=device\n",
                ")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 155,
            "source": [
                "encoder_net = Encoder(\n",
                "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
                ").to(device)\n",
                "\n",
                "decoder_net = Decoder(\n",
                "    input_size_decoder,\n",
                "    decoder_embedding_size,\n",
                "    hidden_size,\n",
                "    output_size,\n",
                "    num_layers,\n",
                "    dec_dropout,\n",
                ").to(device)\n",
                "\n",
                "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
                "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
                "\n",
                "pad_idx = fr_char_vocab.vocab.lookup_indices([\"<pad>\"])\n",
                "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
                "\n",
                "\n",
                "def count_parameters(model):\n",
                "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "\n",
                "print(f'The model has {count_parameters(model):,} trainable parameters')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "The model has 109,977 trainable parameters\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 119,
            "source": [
                "def translate_sentence(model, sentence, french, device, max_length=50):\n",
                "    print(sentence)\n",
                "\n",
                "    # sys.exit()\n",
                "\n",
                "    # Load fr tokenizer\n",
                "    #spacy_ger = spacy.load(\"fr_core_news_lg\")\n",
                "\n",
                "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
                "    if type(sentence) == str:\n",
                "        tokens = [token.text.lower() for token in spacy_lang.tokenizer(sentence)]\n",
                "    else:\n",
                "        tokens = [token.lower() for token in sentence]\n",
                "\n",
                "    print(\"POST TOKENS\")\n",
                "    print(tokens)\n",
                "\n",
                "    # sys.exit()\n",
                "    # Add <SOS> and <EOS> in beginning and end respectively\n",
                "    tokens.insert(0, french.init_token)\n",
                "    tokens.append(french.eos_token)\n",
                "    print(tokens)\n",
                "\n",
                "    # Go through each german token and convert to an index\n",
                "    text_to_indices = [french.vocab.stoi[token] for token in tokens]\n",
                "    print(text_to_indices)\n",
                "    # Convert to Tensor\n",
                "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
                "\n",
                "    # Build encoder hidden, cell state\n",
                "    with torch.no_grad():\n",
                "        hidden, cell = model.encoder(sentence_tensor)\n",
                "\n",
                "    outputs = [french.vocab.stoi[\"<sos>\"]]\n",
                "\n",
                "    for _ in range(max_length):\n",
                "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
                "\n",
                "        with torch.no_grad():\n",
                "            output, hidden, cell = model.decoder(previous_word, hidden, cell)\n",
                "            best_guess = output.argmax(1).item()\n",
                "\n",
                "        outputs.append(best_guess)\n",
                "\n",
                "        # Model predicts it's the end of the sentence\n",
                "        if output.argmax(1).item() == french.vocab.stoi[\"<eos>\"]:\n",
                "            break\n",
                "\n",
                "    translated_sentence = [french.vocab.itos[idx] for idx in outputs]\n",
                "\n",
                "    # remove start token\n",
                "    return translated_sentence[1:]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 117,
            "source": [
                "sentence=\"bonjour comment allez vous \"\n",
                "for epoch in range(num_epochs):\n",
                "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
                "\n",
                "    checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
                "    #save_checkpoint(checkpoint)\n",
                "\n",
                "    model.eval()\n",
                "\n",
                "    translated_sentence = translate_sentence(\n",
                "        model, sentence, french, device, max_length=50\n",
                "    )\n",
                "\n",
                "    print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
                "\n",
                "    model.train()\n",
                "\n",
                "    for batch_idx, batch in enumerate(train_iterator):\n",
                "        # Get input and targets and get to cuda\n",
                "        inp_data = batch.src.to(device)\n",
                "        target = batch.trg.to(device)\n",
                "\n",
                "        # Forward prop\n",
                "        output = model(inp_data, target)\n",
                "\n",
                "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
                "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
                "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
                "        # way that we have output_words * batch_size that we want to send in into\n",
                "        # our cost function, so we need to do some reshapin. While we're at it\n",
                "        # Let's also remove the start token while we're at it\n",
                "        output = output[1:].reshape(-1, output.shape[2])\n",
                "        target = target[1:].reshape(-1)\n",
                "\n",
                "        optimizer.zero_grad()\n",
                "        loss = criterion(output, target)\n",
                "\n",
                "        # Back prop\n",
                "        loss.backward()\n",
                "\n",
                "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
                "        # within a healthy range\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
                "\n",
                "        # Gradient descent step\n",
                "        optimizer.step()\n",
                "\n",
                "        # Plot to tensorboard\n",
                "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
                "        step += 1"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[Epoch 0 / 5]\n",
                        "bonjour comment allez vous \n",
                        "POST TOKENS\n",
                        "['bonjour', 'comment', 'allez', 'vous']\n",
                        "Translated example sentence: \n",
                        " ['m', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p']\n"
                    ]
                },
                {
                    "output_type": "error",
                    "ename": "KeyError",
                    "evalue": "238",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                        "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;31mKeyError\u001b[0m: 238",
                        "\nThe above exception was the direct cause of the following exception:\n",
                        "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-117-ad17c5f108d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Get input and targets and get to cuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0minp_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;31m# fast-forward if loaded from state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36minit_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_state_this_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restored_from_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36mcreate_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m                                  self.batch_size_fn)\n\u001b[1;32m    263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             self.batches = pool(self.data(), self.batch_size,\n\u001b[0m\u001b[1;32m    265\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                                 random_shuffler=self.random_shuffler)\n",
                        "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mKeyError\u001b[0m: 238"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.6.11",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6.11 64-bit ('pytorch-py3.6': conda)"
        },
        "interpreter": {
            "hash": "41e37828fcaddab9e1c456ee9754a83839e4c1413c1aec8ee9b12a956c5f132a"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}